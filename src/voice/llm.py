"""
LLM å°è©±å¼•æ“æ¨¡çµ„
æ”¯æ´ Ollama (æœ¬åœ°) å’Œ Gemini (é›²ç«¯)
"""

import os
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()


class ChatBot:
    """é™ªè®€å°åŠ©æ‰‹å°è©±å¼•æ“"""
    
    def __init__(self, save_conversation: bool = None):
        self.backend = os.getenv('AI_BACKEND', 'ollama').lower()
        self.save_conversation = save_conversation if save_conversation is not None else \
                                 os.getenv('SAVE_CONVERSATION', 'true').lower() == 'true'
        
        # ç³»çµ±æç¤ºè©ï¼šå®šç¾©æ©Ÿå™¨äººçš„è§’è‰²
        self.system_instruction = """ä½ æ˜¯ä¸€å€‹æº«æŸ”ã€æœ‰è€å¿ƒçš„é™ªè®€å°åŠ©æ‰‹ã€‚
ä½ çš„ä»»å‹™æ˜¯é™ªä¼´ 5-12 æ­²çš„å°æœ‹å‹é–±è®€å’Œå­¸ç¿’ã€‚

å›ç­”åŸå‰‡ï¼š
1. ç”¨æ·ºé¡¯æ˜“æ‡‚çš„èªè¨€,é¿å…éæ–¼è‰±æ·±çš„è©å½™
2. å¤šç”¨æ¯”å–»å’Œç”Ÿæ´»åŒ–çš„ä¾‹å­
3. é¼“å‹µå°æœ‹å‹æ€è€ƒ,ä¸ç›´æ¥çµ¦ç­”æ¡ˆ
4. ä¿æŒæ­£å‘ã€é¼“å‹µçš„æ…‹åº¦
5. å›ç­”ç°¡æ½”,æ¯æ¬¡ä¸è¶…é 100 å­—
6. å¦‚æœæ˜¯å±éšªæˆ–ä¸é©ç•¶çš„å•é¡Œ,æº«å’Œåœ°å¼•å°åˆ°æ­£ç¢ºæ–¹å‘"""
        
        # å°è©±æ­·å²
        self.chat_history = []
        
        # æ—¥èªŒç›®éŒ„
        self.log_dir = Path(os.getenv('DATA_DIR', './data')) / 'logs'
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–å°æ‡‰çš„å¾Œç«¯
        if self.backend == 'ollama':
            self._init_ollama()
        elif self.backend == 'gemini':
            self._init_gemini()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ AI å¾Œç«¯: {self.backend}")
    
    def _init_ollama(self):
        """åˆå§‹åŒ– Ollama å¾Œç«¯"""
        try:
            import ollama
            self.client = ollama.Client(host=os.getenv('OLLAMA_HOST', 'http://localhost:11434'))
            self.model_name = os.getenv('OLLAMA_MODEL', os.getenv('OLLAMA_MODEL', 'llama3.2:3b'))
            
            # æ¸¬è©¦é€£ç·š
            try:
                self.client.list()
                print(f"âœ… ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹: {self.model_name}")
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•é€£ç·šåˆ° Ollama: {e}")
                print("ğŸ’¡ è«‹ç¢ºèª Ollama å·²å•Ÿå‹•: ollama serve")
                raise
                
        except ImportError:
            print("âŒ è«‹å…ˆå®‰è£ ollama: pip install ollama")
            raise
    
    def _init_gemini(self):
        """åˆå§‹åŒ– Gemini å¾Œç«¯"""
        try:
            from google import genai
            from google.genai import types
            
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                raise ValueError("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
            
            self.client = genai.Client(api_key=api_key)
            self.model_name = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')
            self.types = types
            
            print(f"âœ… ä½¿ç”¨ Gemini é›²ç«¯æ¨¡å‹: {self.model_name}")
            
        except ImportError:
            print("âŒ è«‹å…ˆå®‰è£ google-genai: pip install google-genai")
            raise
    
    def chat(self, user_message: str) -> str:
        """
        èˆ‡ AI å°è©±
        
        Args:
            user_message: ä½¿ç”¨è€…è¼¸å…¥çš„è¨Šæ¯
            
        Returns:
            AI çš„å›æ‡‰
        """
        try:
            if self.backend == 'ollama':
                return self._chat_ollama(user_message)
            elif self.backend == 'gemini':
                return self._chat_gemini(user_message)
        except Exception as e:
            print(f"âŒ AI å°è©±éŒ¯èª¤: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨æœ‰é»ç´¯äº†ï¼Œç­‰ä¸€ä¸‹å†èŠå¥½å—ï¼Ÿ"
    
    def _chat_ollama(self, user_message: str) -> str:
        """ä½¿ç”¨ Ollama å°è©±"""
        # å»ºç«‹å®Œæ•´çš„å°è©±è¨Šæ¯
        messages = []
        
        # åŠ å…¥ç³»çµ±æŒ‡ç¤ºï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡ï¼‰
        if not self.chat_history:
            messages.append({
                'role': 'system',
                'content': self.system_instruction
            })
        
        # åŠ å…¥æ­·å²å°è©±
        messages.extend(self.chat_history)
        
        # åŠ å…¥ç•¶å‰è¨Šæ¯
        messages.append({
            'role': 'user',
            'content': user_message
        })
        
        # å‘¼å« Ollama API
        response = self.client.chat(
            model=self.model_name,
            messages=messages
        )
        
        ai_response = response['message']['content']
        
        # æ›´æ–°å°è©±æ­·å²
        self.chat_history.append({
            'role': 'user',
            'content': user_message
        })
        self.chat_history.append({
            'role': 'assistant',
            'content': ai_response
        })
        
        # å„²å­˜å°è©±è¨˜éŒ„
        if self.save_conversation:
            self._save_log(user_message, ai_response)
        
        return ai_response
    
    def _chat_gemini(self, user_message: str) -> str:
        """ä½¿ç”¨ Gemini å°è©±"""
        # å»ºç«‹å®Œæ•´çš„å°è©±å…§å®¹
        contents = []
        
        # åŠ å…¥ç³»çµ±æŒ‡ç¤ºï¼ˆä½œç‚ºç¬¬ä¸€æ¢è¨Šæ¯ï¼‰
        if not self.chat_history:
            contents.append(self.types.Content(
                role='user',
                parts=[self.types.Part(text=self.system_instruction)]
            ))
            contents.append(self.types.Content(
                role='model',
                parts=[self.types.Part(text='å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†ï¼æˆ‘æœƒç”¨æ·ºé¡¯æ˜“æ‡‚çš„æ–¹å¼é™ªä¼´å°æœ‹å‹å­¸ç¿’ã€‚')]
            ))
        
        # åŠ å…¥æ­·å²å°è©±
        for msg in self.chat_history:
            contents.append(self.types.Content(
                role=msg['role'] if msg['role'] != 'assistant' else 'model',
                parts=[self.types.Part(text=msg['content'])]
            ))
        
        # åŠ å…¥ç•¶å‰è¨Šæ¯
        contents.append(self.types.Content(
            role='user',
            parts=[self.types.Part(text=user_message)]
        ))
        
        # å‘¼å« Gemini API
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=contents
        )
        
        ai_response = response.text
        
        # æ›´æ–°å°è©±æ­·å²
        self.chat_history.append({
            'role': 'user',
            'content': user_message
        })
        self.chat_history.append({
            'role': 'assistant',
            'content': ai_response
        })
        
        # å„²å­˜å°è©±è¨˜éŒ„
        if self.save_conversation:
            self._save_log(user_message, ai_response)
        
        return ai_response
    
    def _save_log(self, user_msg: str, ai_msg: str):
        """å„²å­˜å°è©±è¨˜éŒ„åˆ°æ—¥èªŒæª”æ¡ˆ"""
        timestamp = datetime.now().strftime("%Y%m%d")
        log_file = self.log_dir / f"conversation_{timestamp}.jsonl"
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "user": user_msg,
            "assistant": ai_msg,
            "backend": self.backend,
            "model": self.model_name
        }
        
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def reset_conversation(self):
        """é‡ç½®å°è©±æ­·å²"""
        self.chat_history = []
        print("âœ… å°è©±æ­·å²å·²æ¸…é™¤")


if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹
    bot = ChatBot()
    response = bot.chat("ç‚ºä»€éº¼å¤©ç©ºæ˜¯è—è‰²çš„ï¼Ÿ")
    print(f"ğŸ¤–: {response}")
