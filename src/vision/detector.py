"""
äººé«”åµæ¸¬æ¨¡çµ„
ä½¿ç”¨ MediaPipe é€²è¡Œå³æ™‚äººé«”éª¨æ¶åµæ¸¬
"""

import os
import cv2
import mediapipe as mp
import numpy as np
from dotenv import load_dotenv

load_dotenv()


class PersonDetector:
    """äººé«”åµæ¸¬èˆ‡è¿½è¹¤å™¨"""
    
    def __init__(self, camera_id: int = None):
        """
        åˆå§‹åŒ–äººé«”åµæ¸¬å™¨
        
        Args:
            camera_id: æ”åƒé ­ IDï¼ˆé è¨­å¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
        """
        self.camera_id = camera_id if camera_id is not None else \
                         int(os.getenv('CAMERA_ID', '0'))
        self.confidence = float(os.getenv('DETECTION_CONFIDENCE', '0.5'))
        
        # åˆå§‹åŒ– MediaPipe Pose
        self.mp_pose = mp.solutions.pose
        self.mp_draw = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=self.confidence,
            min_tracking_confidence=self.confidence
        )
        
        # æ”åƒé ­
        self.cap = None
        
    def start_camera(self):
        """å•Ÿå‹•æ”åƒé ­"""
        self.cap = cv2.VideoCapture(self.camera_id)
        if not self.cap.isOpened():
            raise Exception(f"âŒ ç„¡æ³•é–‹å•Ÿæ”åƒé ­ {self.camera_id}")
        print(f"âœ… æ”åƒé ­ {self.camera_id} å·²å•Ÿå‹•")
    
    def detect_person(self, frame):
        """
        åœ¨å–®å¹€å½±åƒä¸­åµæ¸¬äººé«”
        
        Args:
            frame: OpenCV å½±åƒå¹€
            
        Returns:
            (frame_with_skeleton, person_center, distance_estimate)
            - frame_with_skeleton: ç¹ªè£½éª¨æ¶å¾Œçš„å½±åƒ
            - person_center: äººé«”ä¸­å¿ƒåº§æ¨™ (x, y) æˆ– None
            - distance_estimate: ä¼°è¨ˆè·é›¢ï¼ˆåŸºæ–¼è‚©å¯¬ï¼‰
        """
        # è½‰æ›é¡è‰²ç©ºé–“
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)
        
        person_center = None
        distance_estimate = None
        
        if results.pose_landmarks:
            # ç¹ªè£½éª¨æ¶
            self.mp_draw.draw_landmarks(
                frame,
                results.pose_landmarks,
                self.mp_pose.POSE_CONNECTIONS
            )
            
            # è¨ˆç®—äººé«”ä¸­å¿ƒï¼ˆä½¿ç”¨é¼»å­å’Œé«–éƒ¨ä¸­é»ï¼‰
            landmarks = results.pose_landmarks.landmark
            h, w, _ = frame.shape
            
            nose = landmarks[self.mp_pose.PoseLandmark.NOSE]
            left_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP]
            right_hip = landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP]
            
            center_x = int((nose.x + (left_hip.x + right_hip.x) / 2) / 2 * w)
            center_y = int((nose.y + (left_hip.y + right_hip.y) / 2) / 2 * h)
            person_center = (center_x, center_y)
            
            # ç°¡æ˜“è·é›¢ä¼°ç®—ï¼ˆåŸºæ–¼è‚©å¯¬ï¼‰
            left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
            right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
            shoulder_width_px = abs(left_shoulder.x - right_shoulder.x) * w
            
            # å‡è¨­å¯¦éš›è‚©å¯¬ç´„ 40cmï¼Œç„¦è·ç´„ 600px
            # è·é›¢ â‰ˆ (å¯¦éš›å°ºå¯¸ Ã— ç„¦è·) / åƒç´ å°ºå¯¸
            if shoulder_width_px > 0:
                distance_estimate = (40 * 600) / shoulder_width_px
            
            # ç¹ªè£½ä¸­å¿ƒé»
            cv2.circle(frame, person_center, 10, (0, 255, 0), -1)
            
            # é¡¯ç¤ºè·é›¢è³‡è¨Š
            if distance_estimate:
                cv2.putText(
                    frame,
                    f"Distance: {distance_estimate:.0f}cm",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (0, 255, 0),
                    2
                )
        
        return frame, person_center, distance_estimate
    
    def run_live_detection(self):
        """åŸ·è¡Œå³æ™‚åµæ¸¬ï¼ˆæŒ‰ 'q' é€€å‡ºï¼‰"""
        if self.cap is None:
            self.start_camera()
        
        print("ğŸ¥ å³æ™‚åµæ¸¬å•Ÿå‹•ï¼æŒ‰ 'q' é€€å‡º")
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                print("âŒ ç„¡æ³•è®€å–å½±åƒ")
                break
            
            # åµæ¸¬äººé«”
            frame, center, distance = self.detect_person(frame)
            
            # é¡¯ç¤ºå½±åƒ
            cv2.imshow('Kid Robot - Person Detection', frame)
            
            # æŒ‰ 'q' é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        self.stop_camera()
    
    def stop_camera(self):
        """åœæ­¢æ”åƒé ­"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… æ”åƒé ­å·²é—œé–‰")


if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹
    detector = PersonDetector()
    detector.run_live_detection()
